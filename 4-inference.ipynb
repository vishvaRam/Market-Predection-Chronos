{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "869afd6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "CSV must contain 'timestamp' column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 142\u001b[0m\n\u001b[1;32m    139\u001b[0m     plot_actual_vs_pred(ts_df, preds)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 132\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m--> 132\u001b[0m     ts_df     \u001b[38;5;241m=\u001b[39m \u001b[43mload_eval_ts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     hist_slice \u001b[38;5;241m=\u001b[39m slice_history(ts_df)\n\u001b[1;32m    135\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m TimeSeriesPredictor\u001b[38;5;241m.\u001b[39mload(PREDICTOR_PATH)\n",
      "Cell \u001b[0;32mIn[35], line 62\u001b[0m, in \u001b[0;36mload_eval_ts\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Add timestamp + item_id if missing\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV must contain \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     64\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ITEM_ID_VALUE\n",
      "\u001b[0;31mValueError\u001b[0m: CSV must contain 'timestamp' column"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "PREDICTOR_PATH = \"models/usdinr_chronos_predictor\"\n",
    "EVAL_CSV_PATH  = \"Data/USDINR_day_2025-01-2025-09-Infer-processed.csv\"\n",
    "ITEM_ID_VALUE  = \"USDINR\"\n",
    "TARGET_COL     = \"Close\"\n",
    "PREDICT_LAST_K = 4\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: Add features\n",
    "# ---------------------------\n",
    "def add_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Recompute technical + calendar features safely.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure timestamp is datetime\n",
    "    if not np.issubdtype(df[\"timestamp\"].dtype, np.datetime64):\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop any bad rows with NaT\n",
    "    df = df.dropna(subset=[\"timestamp\"])\n",
    "\n",
    "    # Calendar features\n",
    "    df[\"DayOfWeek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "    df[\"Month\"]     = df[\"timestamp\"].dt.month\n",
    "\n",
    "    # Moving averages\n",
    "    df[\"SMA_3\"]  = df[TARGET_COL].rolling(3).mean()\n",
    "    df[\"SMA_7\"]  = df[TARGET_COL].rolling(7).mean()\n",
    "    df[\"SMA_14\"] = df[TARGET_COL].rolling(14).mean()\n",
    "\n",
    "    # Lag features\n",
    "    df[\"Lag1\"] = df[TARGET_COL].shift(1)\n",
    "    df[\"Lag2\"] = df[TARGET_COL].shift(2)\n",
    "    df[\"Lag3\"] = df[TARGET_COL].shift(3)\n",
    "\n",
    "    df = df.fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "    return df\n",
    "\n",
    "# ---------------------------\n",
    "# Load evaluation CSV\n",
    "# ---------------------------\n",
    "def load_eval_ts() -> TimeSeriesDataFrame:\n",
    "    df = pd.read_csv(EVAL_CSV_PATH)\n",
    "\n",
    "    # Normalize column names\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # Ensure Close exists\n",
    "    if TARGET_COL not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{TARGET_COL}' in {EVAL_CSV_PATH}, found: {df.columns}\")\n",
    "\n",
    "    # Add timestamp + item_id if missing\n",
    "    if \"timestamp\" not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'timestamp' column\")\n",
    "    if \"item_id\" not in df.columns:\n",
    "        df[\"item_id\"] = ITEM_ID_VALUE\n",
    "\n",
    "    # Parse timestamp\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop invalid\n",
    "    df = df.dropna(subset=[\"timestamp\", TARGET_COL])\n",
    "\n",
    "    # Add features\n",
    "    df = add_indicators(df)\n",
    "\n",
    "    # Build TS dataframe\n",
    "    keep_cols = [\"item_id\", \"timestamp\", TARGET_COL] + [\n",
    "        c for c in df.columns if c not in [\"item_id\", \"timestamp\"]\n",
    "    ]\n",
    "    ts_df = TimeSeriesDataFrame.from_data_frame(df[keep_cols], id_column=\"item_id\", timestamp_column=\"timestamp\")\n",
    "    return ts_df\n",
    "\n",
    "# ---------------------------\n",
    "# Slice last history\n",
    "# ---------------------------\n",
    "def slice_history(ts_df: TimeSeriesDataFrame) -> TimeSeriesDataFrame:\n",
    "    end_time = ts_df.index.levels[1].max()\n",
    "    start_time = end_time - pd.Timedelta(days=30)  # last 30 days history\n",
    "    return ts_df.loc[(ITEM_ID_VALUE, slice(start_time, end_time))]\n",
    "\n",
    "# ---------------------------\n",
    "# Build future covariates\n",
    "# ---------------------------\n",
    "def build_future_known(hist_slice: TimeSeriesDataFrame) -> TimeSeriesDataFrame:\n",
    "    last_time = hist_slice.index.levels[1].max()\n",
    "    future_times = pd.date_range(start=last_time + pd.Timedelta(days=1), periods=PREDICT_LAST_K, freq=\"D\")\n",
    "\n",
    "    future_df = pd.DataFrame({\n",
    "        \"item_id\": ITEM_ID_VALUE,\n",
    "        \"timestamp\": future_times\n",
    "    })\n",
    "\n",
    "    # Calendar features\n",
    "    future_df[\"DayOfWeek\"] = future_df[\"timestamp\"].dt.dayofweek\n",
    "    future_df[\"Month\"]     = future_df[\"timestamp\"].dt.month\n",
    "\n",
    "    return TimeSeriesDataFrame.from_data_frame(future_df, id_column=\"item_id\", timestamp_column=\"timestamp\")\n",
    "\n",
    "# ---------------------------\n",
    "# Predict last K days\n",
    "# ---------------------------\n",
    "def predict_last_k(predictor, hist_slice):\n",
    "    future_known = build_future_known(hist_slice)\n",
    "    return predictor.predict(data=hist_slice, known_covariates=future_known)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot actual vs predicted\n",
    "# ---------------------------\n",
    "def plot_actual_vs_pred(ts_df, preds):\n",
    "    actual = ts_df.loc[ITEM_ID_VALUE][TARGET_COL]\n",
    "    pred   = preds.loc[ITEM_ID_VALUE][\"mean\"]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=actual.index, y=actual, mode=\"lines+markers\", name=\"Actual\"))\n",
    "    fig.add_trace(go.Scatter(x=pred.index,   y=pred,   mode=\"lines+markers\", name=\"Predicted\"))\n",
    "    fig.update_layout(title=\"USDINR Actual vs Predicted\", xaxis_title=\"Date\", yaxis_title=TARGET_COL)\n",
    "    fig.show()\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "def main():\n",
    "    ts_df     = load_eval_ts()\n",
    "    hist_slice = slice_history(ts_df)\n",
    "\n",
    "    predictor = TimeSeriesPredictor.load(PREDICTOR_PATH)\n",
    "    preds     = predict_last_k(predictor, hist_slice)\n",
    "\n",
    "    print(\"Predictions:\\n\", preds)\n",
    "    plot_actual_vs_pred(ts_df, preds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9461e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
