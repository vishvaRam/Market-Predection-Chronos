{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "869afd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'IRREG' has been resampled to frequency 'D'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting USDINR Inference Pipeline...\n",
      "==================================================\n",
      "ğŸ”„ Loading model from: models/usdinr_chronos_predictor\n",
      "âœ… Model loaded successfully!\n",
      "ğŸ“Š Loading inference data from: Data/USDINR_day_2025-01-2025-09-Infer-processed.csv\n",
      "âœ… Data prepared: (121, 13)\n",
      "ğŸ“Š Known covariates: 12\n",
      "ğŸ“… Date range: 2025-03-12 00:00:00 to 2025-08-29 00:00:00\n",
      "ğŸ”® Generating future forecasts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Predictions generated: (4, 10)\n",
      "ğŸ’¾ Predictions saved to: usdinr_inference_predictions.csv\n",
      "==================================================\n",
      "ğŸ¯ Inference completed successfully!\n",
      "\n",
      "ğŸ“ˆ Future 4 days USDINR Predictions:\n",
      "  ğŸ“… 2025-08-30: 87.51659 INR\n",
      "  ğŸ“… 2025-08-31: 87.49575 INR\n",
      "  ğŸ“… 2025-09-01: 87.47936 INR\n",
      "  ğŸ“… 2025-09-02: 87.50985 INR\n",
      "\n",
      "ğŸ¯ Prediction Ranges (10%-90% confidence):\n",
      "  ğŸ“… 2025-08-30: 87.31823 - 87.75201 INR\n",
      "  ğŸ“… 2025-08-31: 87.27477 - 87.77258 INR\n",
      "  ğŸ“… 2025-09-01: 87.26141 - 87.76715 INR\n",
      "  ğŸ“… 2025-09-02: 87.24723 - 87.80813 INR\n",
      "\n",
      "ğŸ“Š Available prediction quantiles: ['mean', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9']\n",
      "\n",
      "ğŸ¯ SUCCESS! Next 4 days USDINR predictions ready!\n",
      "ğŸ“Š Check 'usdinr_inference_predictions.csv' for detailed quantile forecasts\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "AutoGluon Chronos USDINR Inference Script - Matching Training Structure\n",
    "Loads trained model and runs predictions using known_covariates approach\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def prepare_inference_data(file_path):\n",
    "    \"\"\"\n",
    "    Prepare USDINR inference data similar to training data preparation\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to CSV file with market data\n",
    "    \n",
    "    Returns:\n",
    "        ts_df: TimeSeriesDataFrame for inference\n",
    "        known_covariates: List of covariate column names\n",
    "    \"\"\"\n",
    "    # Load processed data\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Handle date column (Price column in your dataset)\n",
    "    if 'Price' in data.columns:\n",
    "        data['timestamp'] = pd.to_datetime(data['Price'])\n",
    "    else:\n",
    "        # Fallback for other date column names\n",
    "        date_cols = [col for col in data.columns if any(x in col.lower() for x in ['date', 'time', 'timestamp'])]\n",
    "        if date_cols:\n",
    "            data['timestamp'] = pd.to_datetime(data[date_cols[0]])\n",
    "        else:\n",
    "            raise ValueError(\"No date column found\")\n",
    "    \n",
    "    # Set item_id and target\n",
    "    data['item_id'] = 'USDINR'\n",
    "    data['target'] = data['Close']  # Target is Close price\n",
    "    \n",
    "    # Define known covariates (same as training)\n",
    "    known_covariates = [\n",
    "        'Close', 'High', 'Low', 'Volume', 'SMA_20', 'SMA_50', \n",
    "        'EMA_12', 'EMA_26', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_hist'\n",
    "    ]\n",
    "    \n",
    "    # Select required columns\n",
    "    required_cols = ['item_id', 'timestamp', 'target'] + known_covariates\n",
    "    available_cols = [col for col in required_cols if col in data.columns]\n",
    "    \n",
    "    if len(available_cols) < len(required_cols):\n",
    "        missing_cols = set(required_cols) - set(available_cols)\n",
    "        print(f\"âš ï¸  Missing columns: {missing_cols}\")\n",
    "    \n",
    "    data_processed = data[available_cols].copy()\n",
    "    \n",
    "    # Sort by timestamp and remove NaN targets\n",
    "    data_processed = data_processed.sort_values('timestamp')\n",
    "    data_processed = data_processed.dropna(subset=['target'])\n",
    "    \n",
    "    # Convert to TimeSeriesDataFrame (using same method as training)\n",
    "    ts_df = TimeSeriesDataFrame.from_data_frame(\n",
    "        data_processed,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp'\n",
    "    )\n",
    "    \n",
    "    return ts_df, known_covariates\n",
    "\n",
    "def inference_usdinr_forecaster(model_path, inference_data_path, prediction_length=4):\n",
    "    \"\"\"\n",
    "    Run USDINR inference using trained Chronos model - matches training structure\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to trained AutoGluon model\n",
    "        inference_data_path: Path to inference dataset\n",
    "        prediction_length: Number of future days to predict\n",
    "    \n",
    "    Returns:\n",
    "        predictions: Future USDINR predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Starting USDINR Inference Pipeline...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load trained model\n",
    "    print(f\"ğŸ”„ Loading model from: {model_path}\")\n",
    "    try:\n",
    "        predictor = TimeSeriesPredictor.load(model_path)\n",
    "        print(\"âœ… Model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Load and prepare inference data\n",
    "    print(f\"ğŸ“Š Loading inference data from: {inference_data_path}\")\n",
    "    try:\n",
    "        ts_df, known_covariates = prepare_inference_data(inference_data_path)\n",
    "        print(f\"âœ… Data prepared: {ts_df.shape}\")\n",
    "        print(f\"ğŸ“Š Known covariates: {len(known_covariates)}\")\n",
    "        print(f\"ğŸ“… Date range: {ts_df.index.get_level_values('timestamp').min()} to {ts_df.index.get_level_values('timestamp').max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error preparing data: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Generate future forecasts (following training approach)\n",
    "    print(\"ğŸ”® Generating future forecasts...\")\n",
    "    \n",
    "    try:\n",
    "        # Create future known covariates by forward-filling last known values\n",
    "        last_timestamp = ts_df.index.get_level_values('timestamp')[-1]\n",
    "        future_timestamps = [last_timestamp + pd.Timedelta(days=i) for i in range(1, prediction_length + 1)]\n",
    "        \n",
    "        future_df = pd.DataFrame({\n",
    "            'timestamp': future_timestamps,\n",
    "            'item_id': 'USDINR'\n",
    "        })\n",
    "        \n",
    "        # Forward-fill covariates from last row (same as training)\n",
    "        last_values = ts_df.iloc[-1]\n",
    "        for col in known_covariates:\n",
    "            if col in ts_df.columns:\n",
    "                future_df[col] = last_values[col]\n",
    "        \n",
    "        # Update time-based covariates if they exist\n",
    "        if 'Hour' in ts_df.columns:\n",
    "            future_df['Hour'] = 0  # Market open hour\n",
    "        if 'DayOfWeek' in ts_df.columns:\n",
    "            future_df['DayOfWeek'] = future_df['timestamp'].dt.dayofweek\n",
    "        if 'Month' in ts_df.columns:\n",
    "            future_df['Month'] = future_df['timestamp'].dt.month\n",
    "        \n",
    "        # Create TimeSeriesDataFrame for known covariates (same as training)\n",
    "        future_known = TimeSeriesDataFrame.from_data_frame(\n",
    "            future_df,\n",
    "            id_column='item_id',\n",
    "            timestamp_column='timestamp'\n",
    "        )\n",
    "        \n",
    "        # Make predictions using known_covariates (same as training)\n",
    "        predictions = predictor.predict(\n",
    "            data=ts_df,\n",
    "            known_covariates=future_known\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Predictions generated: {predictions.shape}\")\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def save_and_display_predictions(predictions, output_path='usdinr_inference_predictions.csv'):\n",
    "    \"\"\"Save and display predictions\"\"\"\n",
    "    \n",
    "    if predictions is None:\n",
    "        print(\"âŒ No predictions to save\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Save predictions\n",
    "        predictions.to_csv(output_path)\n",
    "        print(f\"ğŸ’¾ Predictions saved to: {output_path}\")\n",
    "        \n",
    "        # Display predictions\n",
    "        print(\"=\" * 50)\n",
    "        print(\"ğŸ¯ Inference completed successfully!\")\n",
    "        print(f\"\\nğŸ“ˆ Future {len(predictions)} days USDINR Predictions:\")\n",
    "        \n",
    "        # Show all predictions with proper formatting\n",
    "        for i, (idx, row) in enumerate(predictions.iterrows()):\n",
    "            if hasattr(idx, '__len__') and len(idx) > 1:\n",
    "                timestamp = idx[1]  # MultiIndex (item_id, timestamp)\n",
    "            else:\n",
    "                timestamp = idx\n",
    "            \n",
    "            # Show mean prediction (0.5 quantile) and confidence interval\n",
    "            if 'mean' in row.index:\n",
    "                mean_pred = row['mean']\n",
    "            elif '0.5' in row.index:\n",
    "                mean_pred = row['0.5']\n",
    "            else:\n",
    "                mean_pred = row.iloc[len(row)//2]  # Middle value\n",
    "            \n",
    "            print(f\"  ğŸ“… {timestamp.strftime('%Y-%m-%d')}: {mean_pred:.5f} INR\")\n",
    "        \n",
    "        # Show confidence intervals if available\n",
    "        if '0.1' in predictions.columns and '0.9' in predictions.columns:\n",
    "            print(f\"\\nğŸ¯ Prediction Ranges (10%-90% confidence):\")\n",
    "            for i, (idx, row) in enumerate(predictions.iterrows()):\n",
    "                if hasattr(idx, '__len__') and len(idx) > 1:\n",
    "                    timestamp = idx[1]\n",
    "                else:\n",
    "                    timestamp = idx\n",
    "                \n",
    "                low_pred = row['0.1']\n",
    "                high_pred = row['0.9']\n",
    "                print(f\"  ğŸ“… {timestamp.strftime('%Y-%m-%d')}: {low_pred:.5f} - {high_pred:.5f} INR\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Available prediction quantiles: {list(predictions.columns)}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving predictions: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = \"models/usdinr_chronos_predictor\"\n",
    "    DATA_PATH = \"Data/USDINR_day_2025-01-2025-09-Infer-processed.csv\"\n",
    "    OUTPUT_PATH = \"usdinr_inference_predictions.csv\"\n",
    "    PREDICTION_LENGTH = 4  # Next 4 days\n",
    "    \n",
    "    # Run inference\n",
    "    predictions = inference_usdinr_forecaster(\n",
    "        model_path=MODEL_PATH,\n",
    "        inference_data_path=DATA_PATH,\n",
    "        prediction_length=PREDICTION_LENGTH\n",
    "    )\n",
    "    \n",
    "    # Save and display results\n",
    "    if predictions is not None:\n",
    "        success = save_and_display_predictions(predictions, OUTPUT_PATH)\n",
    "        if success:\n",
    "            print(f\"\\nğŸ¯ SUCCESS! Next {PREDICTION_LENGTH} days USDINR predictions ready!\")\n",
    "            print(f\"ğŸ“Š Check '{OUTPUT_PATH}' for detailed quantile forecasts\")\n",
    "        else:\n",
    "            print(\"âŒ Failed to save predictions\")\n",
    "    else:\n",
    "        print(\"âŒ Inference failed - check error messages above\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ad1750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'IRREG' has been resampled to frequency 'D'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Trimming last 4 days from Data/USDINR_day_2025-01-2025-09-Infer-processed.csv\n",
      "âœ… Trimmed data saved to USDINR_trimmed_for_inference.csv\n",
      "ğŸ“Š Removed 4 days for backtesting\n",
      "ğŸ“… Backtesting dates: 2025-08-26 to 2025-08-29\n",
      "ğŸš€ Starting USDINR Inference Pipeline...\n",
      "==================================================\n",
      "ğŸ”„ Loading model from: models/usdinr_chronos_predictor\n",
      "âœ… Model loaded successfully!\n",
      "ğŸ“Š Loading inference data from: USDINR_trimmed_for_inference.csv\n",
      "âœ… Data prepared: (117, 13)\n",
      "ğŸ“Š Known covariates: 12\n",
      "ğŸ“… Date range: 2025-03-12 00:00:00 to 2025-08-25 00:00:00\n",
      "ğŸ”® Generating future forecasts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Predictions generated: (4, 10)\n",
      "ğŸ“Š Creating predictions vs actual comparison...\n",
      "============================================================\n",
      "ğŸ¯ BACKTESTING RESULTS\n",
      "============================================================\n",
      "ğŸ“… 2025-08-26:\n",
      "   Predicted: 87.19531 INR\n",
      "   Actual:    87.60860 INR\n",
      "   Error:     0.41328 INR (0.47%)\n",
      "   In Range:  âŒ NO\n",
      "\n",
      "ğŸ“… 2025-08-27:\n",
      "   Predicted: 87.18262 INR\n",
      "   Actual:    87.60070 INR\n",
      "   Error:     0.41808 INR (0.48%)\n",
      "   In Range:  âŒ NO\n",
      "\n",
      "ğŸ“… 2025-08-28:\n",
      "   Predicted: 87.16073 INR\n",
      "   Actual:    87.65910 INR\n",
      "   Error:     0.49837 INR (0.57%)\n",
      "   In Range:  âŒ NO\n",
      "\n",
      "ğŸ“… 2025-08-29:\n",
      "   Predicted: 87.16889 INR\n",
      "   Actual:    87.59170 INR\n",
      "   Error:     0.42281 INR (0.48%)\n",
      "   In Range:  âŒ NO\n",
      "\n",
      "ğŸ“ˆ SUMMARY METRICS:\n",
      "   Mean Absolute Error (MAE): 0.43814 INR\n",
      "   Mean Absolute Percentage Error (MAPE): 0.50%\n",
      "   Predictions within 10%-90% range: 0.0%\n",
      "\n",
      "ğŸ’¾ Detailed comparison saved to: USDINR_predictions_vs_actual.csv\n",
      "\n",
      "ğŸ¯ SUCCESS! Backtesting completed!\n",
      "ğŸ“Š Check 'USDINR_predictions_vs_actual.csv' for detailed predictions vs actual comparison\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "AutoGluon Chronos USDINR Inference Script - WITH BACKTESTING\n",
    "Trims last N days, predicts them, and compares with actual values\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def trim_data_for_backtesting(original_path, trim_last_n_days=4, output_path='USDINR_trimmed_for_inference.csv'):\n",
    "    \"\"\"\n",
    "    Remove last N days from dataset for backtesting\n",
    "    \n",
    "    Args:\n",
    "        original_path: Path to original dataset\n",
    "        trim_last_n_days: Number of days to remove from end\n",
    "        output_path: Path to save trimmed dataset\n",
    "    \n",
    "    Returns:\n",
    "        trimmed_path: Path to trimmed dataset\n",
    "        actual_data: DataFrame with actual values for removed days\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“‚ Trimming last {trim_last_n_days} days from {original_path}\")\n",
    "    \n",
    "    # Load full data\n",
    "    df = pd.read_csv(original_path)\n",
    "    \n",
    "    # Convert 'Price' col to datetime\n",
    "    if 'Price' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['Price'])\n",
    "    else:\n",
    "        date_cols = [col for col in df.columns if any(x in col.lower() for x in ['date', 'time', 'timestamp'])]\n",
    "        if date_cols:\n",
    "            df['timestamp'] = pd.to_datetime(df[date_cols[0]])\n",
    "        else:\n",
    "            raise ValueError(\"No date column found for trimming.\")\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df = df.sort_values('timestamp')\n",
    "    \n",
    "    # Get last N days for comparison\n",
    "    unique_dates = sorted(df['timestamp'].unique())\n",
    "    trim_dates = unique_dates[-trim_last_n_days:]\n",
    "    \n",
    "    # Split data\n",
    "    df_trimmed = df[~df['timestamp'].isin(trim_dates)]\n",
    "    actual_data = df[df['timestamp'].isin(trim_dates)][['timestamp', 'Close', 'High', 'Low']].copy()\n",
    "    \n",
    "    # Save trimmed data\n",
    "    df_trimmed.drop('timestamp', axis=1).to_csv(output_path, index=False)  # Remove temp timestamp col\n",
    "    \n",
    "    print(f\"âœ… Trimmed data saved to {output_path}\")\n",
    "    print(f\"ğŸ“Š Removed {len(actual_data)} days for backtesting\")\n",
    "    print(f\"ğŸ“… Backtesting dates: {trim_dates[0].strftime('%Y-%m-%d')} to {trim_dates[-1].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    return output_path, actual_data\n",
    "\n",
    "def prepare_inference_data(file_path):\n",
    "    \"\"\"Same as before - prepare data for inference\"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    if 'Price' in data.columns:\n",
    "        data['timestamp'] = pd.to_datetime(data['Price'])\n",
    "    else:\n",
    "        date_cols = [col for col in data.columns if any(x in col.lower() for x in ['date', 'time', 'timestamp'])]\n",
    "        if date_cols:\n",
    "            data['timestamp'] = pd.to_datetime(data[date_cols[0]])\n",
    "        else:\n",
    "            raise ValueError(\"No date column found\")\n",
    "    \n",
    "    data['item_id'] = 'USDINR'\n",
    "    data['target'] = data['Close']\n",
    "    \n",
    "    known_covariates = [\n",
    "        'Close', 'High', 'Low', 'Volume', 'SMA_20', 'SMA_50', \n",
    "        'EMA_12', 'EMA_26', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_hist'\n",
    "    ]\n",
    "    \n",
    "    required_cols = ['item_id', 'timestamp', 'target'] + known_covariates\n",
    "    available_cols = [col for col in required_cols if col in data.columns]\n",
    "    \n",
    "    if len(available_cols) < len(required_cols):\n",
    "        missing_cols = set(required_cols) - set(available_cols)\n",
    "        print(f\"âš ï¸  Missing columns: {missing_cols}\")\n",
    "    \n",
    "    data_processed = data[available_cols].copy()\n",
    "    data_processed = data_processed.sort_values('timestamp')\n",
    "    data_processed = data_processed.dropna(subset=['target'])\n",
    "    \n",
    "    ts_df = TimeSeriesDataFrame.from_data_frame(\n",
    "        data_processed,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp'\n",
    "    )\n",
    "    \n",
    "    return ts_df, known_covariates\n",
    "\n",
    "def inference_usdinr_forecaster(model_path, inference_data_path, prediction_length=4):\n",
    "    \"\"\"Same inference function as before\"\"\"\n",
    "    print(\"ğŸš€ Starting USDINR Inference Pipeline...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"ğŸ”„ Loading model from: {model_path}\")\n",
    "    try:\n",
    "        predictor = TimeSeriesPredictor.load(model_path)\n",
    "        print(\"âœ… Model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ğŸ“Š Loading inference data from: {inference_data_path}\")\n",
    "    try:\n",
    "        ts_df, known_covariates = prepare_inference_data(inference_data_path)\n",
    "        print(f\"âœ… Data prepared: {ts_df.shape}\")\n",
    "        print(f\"ğŸ“Š Known covariates: {len(known_covariates)}\")\n",
    "        print(f\"ğŸ“… Date range: {ts_df.index.get_level_values('timestamp').min()} to {ts_df.index.get_level_values('timestamp').max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error preparing data: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸ”® Generating future forecasts...\")\n",
    "    \n",
    "    try:\n",
    "        last_timestamp = ts_df.index.get_level_values('timestamp')[-1]\n",
    "        future_timestamps = [last_timestamp + pd.Timedelta(days=i) for i in range(1, prediction_length + 1)]\n",
    "        \n",
    "        future_df = pd.DataFrame({\n",
    "            'timestamp': future_timestamps,\n",
    "            'item_id': 'USDINR'\n",
    "        })\n",
    "        \n",
    "        last_values = ts_df.iloc[-1]\n",
    "        for col in known_covariates:\n",
    "            if col in ts_df.columns:\n",
    "                future_df[col] = last_values[col]\n",
    "        \n",
    "        if 'Hour' in ts_df.columns:\n",
    "            future_df['Hour'] = 0\n",
    "        if 'DayOfWeek' in ts_df.columns:\n",
    "            future_df['DayOfWeek'] = future_df['timestamp'].dt.dayofweek\n",
    "        if 'Month' in ts_df.columns:\n",
    "            future_df['Month'] = future_df['timestamp'].dt.month\n",
    "        \n",
    "        future_known = TimeSeriesDataFrame.from_data_frame(\n",
    "            future_df,\n",
    "            id_column='item_id',\n",
    "            timestamp_column='timestamp'\n",
    "        )\n",
    "        \n",
    "        predictions = predictor.predict(\n",
    "            data=ts_df,\n",
    "            known_covariates=future_known\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Predictions generated: {predictions.shape}\")\n",
    "        return predictions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_comparison_csv(predictions, actual_data, output_path='USDINR_predictions_vs_actual.csv'):\n",
    "    \"\"\"\n",
    "    Create comparison CSV with predictions vs actual values\n",
    "    \n",
    "    Args:\n",
    "        predictions: Model predictions DataFrame\n",
    "        actual_data: Actual values DataFrame\n",
    "        output_path: Output CSV path\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š Creating predictions vs actual comparison...\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare predictions data\n",
    "        pred_data = []\n",
    "        for i, (idx, row) in enumerate(predictions.iterrows()):\n",
    "            if hasattr(idx, '__len__') and len(idx) > 1:\n",
    "                timestamp = idx[1]\n",
    "            else:\n",
    "                timestamp = idx\n",
    "            \n",
    "            pred_record = {\n",
    "                'Date': timestamp.strftime('%Y-%m-%d'),\n",
    "                'Predicted_Close': row.get('0.5', row.get('mean', row.iloc[4])),\n",
    "                'Predicted_Low_10%': row.get('0.1', 'N/A'),\n",
    "                'Predicted_High_90%': row.get('0.9', 'N/A'),\n",
    "                'Prediction_Range': f\"{row.get('0.1', 'N/A'):.4f} - {row.get('0.9', 'N/A'):.4f}\" if row.get('0.1') and row.get('0.9') else 'N/A'\n",
    "            }\n",
    "            pred_data.append(pred_record)\n",
    "        \n",
    "        pred_df = pd.DataFrame(pred_data)\n",
    "        \n",
    "        # Prepare actual data\n",
    "        actual_df = actual_data.copy()\n",
    "        actual_df['Date'] = actual_df['timestamp'].dt.strftime('%Y-%m-%d')\n",
    "        actual_df = actual_df.rename(columns={'Close': 'Actual_Close', 'High': 'Actual_High', 'Low': 'Actual_Low'})\n",
    "        actual_df = actual_df[['Date', 'Actual_Close', 'Actual_High', 'Actual_Low']]\n",
    "        \n",
    "        # Merge predictions and actuals\n",
    "        comparison_df = pd.merge(pred_df, actual_df, on='Date', how='outer')\n",
    "        \n",
    "        # Calculate accuracy metrics\n",
    "        comparison_df['Absolute_Error'] = abs(comparison_df['Predicted_Close'] - comparison_df['Actual_Close'])\n",
    "        comparison_df['Percentage_Error'] = (comparison_df['Absolute_Error'] / comparison_df['Actual_Close']) * 100\n",
    "        comparison_df['Within_Range'] = (\n",
    "            (comparison_df['Actual_Close'] >= comparison_df['Predicted_Low_10%'].astype(float)) & \n",
    "            (comparison_df['Actual_Close'] <= comparison_df['Predicted_High_90%'].astype(float))\n",
    "        )\n",
    "        \n",
    "        # Save comparison\n",
    "        comparison_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ğŸ¯ BACKTESTING RESULTS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for _, row in comparison_df.iterrows():\n",
    "            print(f\"ğŸ“… {row['Date']}:\")\n",
    "            print(f\"   Predicted: {row['Predicted_Close']:.5f} INR\")\n",
    "            print(f\"   Actual:    {row['Actual_Close']:.5f} INR\")\n",
    "            print(f\"   Error:     {row['Absolute_Error']:.5f} INR ({row['Percentage_Error']:.2f}%)\")\n",
    "            print(f\"   In Range:  {'âœ… YES' if row['Within_Range'] else 'âŒ NO'}\")\n",
    "            print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        mae = comparison_df['Absolute_Error'].mean()\n",
    "        mape = comparison_df['Percentage_Error'].mean()\n",
    "        accuracy_rate = comparison_df['Within_Range'].mean() * 100\n",
    "        \n",
    "        print(\"ğŸ“ˆ SUMMARY METRICS:\")\n",
    "        print(f\"   Mean Absolute Error (MAE): {mae:.5f} INR\")\n",
    "        print(f\"   Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "        print(f\"   Predictions within 10%-90% range: {accuracy_rate:.1f}%\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ Detailed comparison saved to: {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating comparison: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# MAIN EXECUTION WITH BACKTESTING\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = \"models/usdinr_chronos_predictor\"\n",
    "    ORIGINAL_DATA_PATH = \"Data/USDINR_day_2025-01-2025-09-Infer-processed.csv\"  # Updated path\n",
    "    TRIMMED_DATA_PATH = \"USDINR_trimmed_for_inference.csv\"\n",
    "    COMPARISON_OUTPUT = \"USDINR_predictions_vs_actual.csv\"\n",
    "    PREDICTION_LENGTH = 4  # Next 4 days\n",
    "    \n",
    "    # Step 1: Trim data for backtesting\n",
    "    trimmed_path, actual_data = trim_data_for_backtesting(\n",
    "        ORIGINAL_DATA_PATH, \n",
    "        trim_last_n_days=PREDICTION_LENGTH,\n",
    "        output_path=TRIMMED_DATA_PATH\n",
    "    )\n",
    "    \n",
    "    # Step 2: Run inference on trimmed data\n",
    "    predictions = inference_usdinr_forecaster(\n",
    "        model_path=MODEL_PATH,\n",
    "        inference_data_path=trimmed_path,\n",
    "        prediction_length=PREDICTION_LENGTH\n",
    "    )\n",
    "    \n",
    "    # Step 3: Compare predictions with actual values\n",
    "    if predictions is not None:\n",
    "        success = create_comparison_csv(predictions, actual_data, COMPARISON_OUTPUT)\n",
    "        if success:\n",
    "            print(f\"\\nğŸ¯ SUCCESS! Backtesting completed!\")\n",
    "            print(f\"ğŸ“Š Check '{COMPARISON_OUTPUT}' for detailed predictions vs actual comparison\")\n",
    "        else:\n",
    "            print(\"âŒ Failed to create comparison\")\n",
    "    else:\n",
    "        print(\"âŒ Inference failed - check error messages above\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
